{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistema de Compliance LGPD\n",
    "\n",
    "## Demonstra√ß√£o - Auditoria e Anonimiza√ß√£o de Dados Pessoais\n",
    "\n",
    "Este notebook demonstra as funcionalidades do sistema de compliance:\n",
    "\n",
    "1. **Scanner de PII**: Detecta dados pessoais identific√°veis\n",
    "2. **Classifica√ß√£o de Risco**: Categoriza dados por n√≠vel de sensibilidade\n",
    "3. **Anonimiza√ß√£o**: 7 m√©todos diferentes de prote√ß√£o\n",
    "4. **Relat√≥rios**: Documenta√ß√£o para auditoria\n",
    "\n",
    "### Refer√™ncias LGPD\n",
    "- **Art. 5¬∫**: Defini√ß√£o de dados pessoais e sens√≠veis\n",
    "- **Art. 6¬∫**: Princ√≠pios (finalidade, necessidade, transpar√™ncia)\n",
    "- **Art. 12**: Anonimiza√ß√£o como alternativa ao consentimento\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Instalar depend√™ncias (necess√°rio no Google Colab)\n!pip install faker -q\n\n# Imports\nimport pandas as pd\nimport numpy as np\nfrom faker import Faker\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport warnings\nimport re\nimport hashlib\nfrom enum import Enum\nfrom dataclasses import dataclass, field\nfrom typing import List, Dict, Optional, Any\nfrom datetime import datetime\n\nwarnings.filterwarnings('ignore')\n\n# ============================================================\n# CLASSES DO SISTEMA DE COMPLIANCE (vers√£o simplificada para demo)\n# ============================================================\n\nclass PIIType(Enum):\n    \"\"\"Tipos de dados pessoais identific√°veis\"\"\"\n    CPF = \"cpf\"\n    CNPJ = \"cnpj\"\n    EMAIL = \"email\"\n    PHONE = \"telefone\"\n    NAME = \"nome\"\n    ADDRESS = \"endereco\"\n    DATE_BIRTH = \"data_nascimento\"\n    SALARY = \"salario\"\n    CEP = \"cep\"\n    GENERIC = \"generico\"\n\nclass RiskLevel(Enum):\n    \"\"\"N√≠veis de risco LGPD\"\"\"\n    CRITICO = \"critico\"\n    ALTO = \"alto\"\n    MEDIO = \"medio\"\n    BAIXO = \"baixo\"\n\nclass AnonymizationMethod(Enum):\n    \"\"\"M√©todos de anonimiza√ß√£o dispon√≠veis\"\"\"\n    MASK = \"mask\"\n    HASH = \"hash\"\n    PSEUDONYMIZE = \"pseudonymize\"\n    GENERALIZE = \"generalize\"\n    SUPPRESS = \"suppress\"\n    TOKENIZE = \"tokenize\"\n    NOISE = \"noise\"\n\n@dataclass\nclass PIIDetection:\n    \"\"\"Resultado de detec√ß√£o de PII\"\"\"\n    column: str\n    pii_type: PIIType\n    risk_level: RiskLevel\n    detection_method: str\n    count: int\n    percentage: float\n    sample_values: List[str] = field(default_factory=list)\n\n@dataclass\nclass ScanResult:\n    \"\"\"Resultado completo do scan\"\"\"\n    source_name: str\n    total_rows: int\n    columns_scanned: int\n    pii_found: List[PIIDetection]\n    risk_summary: Dict[str, int]\n    recommendations: List[str]\n    scan_duration_seconds: float\n\nclass PIIScanner:\n    \"\"\"Scanner de dados pessoais identific√°veis\"\"\"\n    \n    PATTERNS = {\n        PIIType.CPF: r'\\d{3}\\.?\\d{3}\\.?\\d{3}-?\\d{2}',\n        PIIType.CNPJ: r'\\d{2}\\.?\\d{3}\\.?\\d{3}/?\\d{4}-?\\d{2}',\n        PIIType.EMAIL: r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}',\n        PIIType.PHONE: r'(\\(?\\d{2}\\)?\\s?)?(\\d{4,5}-?\\d{4})',\n        PIIType.CEP: r'\\d{5}-?\\d{3}',\n    }\n    \n    COLUMN_KEYWORDS = {\n        'nome': (PIIType.NAME, RiskLevel.ALTO),\n        'name': (PIIType.NAME, RiskLevel.ALTO),\n        'cpf': (PIIType.CPF, RiskLevel.CRITICO),\n        'cnpj': (PIIType.CNPJ, RiskLevel.CRITICO),\n        'email': (PIIType.EMAIL, RiskLevel.ALTO),\n        'telefone': (PIIType.PHONE, RiskLevel.MEDIO),\n        'phone': (PIIType.PHONE, RiskLevel.MEDIO),\n        'endereco': (PIIType.ADDRESS, RiskLevel.MEDIO),\n        'address': (PIIType.ADDRESS, RiskLevel.MEDIO),\n        'nascimento': (PIIType.DATE_BIRTH, RiskLevel.MEDIO),\n        'birth': (PIIType.DATE_BIRTH, RiskLevel.MEDIO),\n        'salario': (PIIType.SALARY, RiskLevel.ALTO),\n        'salary': (PIIType.SALARY, RiskLevel.ALTO),\n        'cep': (PIIType.CEP, RiskLevel.BAIXO),\n    }\n    \n    def scan(self, df: pd.DataFrame, source_name: str = \"unknown\") -> ScanResult:\n        start_time = datetime.now()\n        pii_found = []\n        \n        for col in df.columns:\n            col_lower = col.lower()\n            \n            # Verificar por nome da coluna\n            for keyword, (pii_type, risk) in self.COLUMN_KEYWORDS.items():\n                if keyword in col_lower:\n                    sample = df[col].dropna().head(3).astype(str).tolist()\n                    pii_found.append(PIIDetection(\n                        column=col,\n                        pii_type=pii_type,\n                        risk_level=risk,\n                        detection_method=\"keyword_match\",\n                        count=df[col].notna().sum(),\n                        percentage=round(df[col].notna().sum() / len(df) * 100, 1),\n                        sample_values=sample\n                    ))\n                    break\n            else:\n                # Verificar por padr√£o regex\n                if df[col].dtype == 'object':\n                    for pii_type, pattern in self.PATTERNS.items():\n                        matches = df[col].astype(str).str.contains(pattern, regex=True, na=False)\n                        if matches.sum() > len(df) * 0.5:\n                            risk = RiskLevel.CRITICO if pii_type in [PIIType.CPF, PIIType.CNPJ] else RiskLevel.MEDIO\n                            sample = df[col][matches].head(3).astype(str).tolist()\n                            pii_found.append(PIIDetection(\n                                column=col,\n                                pii_type=pii_type,\n                                risk_level=risk,\n                                detection_method=\"pattern_match\",\n                                count=matches.sum(),\n                                percentage=round(matches.sum() / len(df) * 100, 1),\n                                sample_values=sample\n                            ))\n                            break\n        \n        risk_summary = {}\n        for pii in pii_found:\n            risk_summary[pii.risk_level.value] = risk_summary.get(pii.risk_level.value, 0) + 1\n        \n        recommendations = self._generate_recommendations(pii_found)\n        duration = (datetime.now() - start_time).total_seconds()\n        \n        return ScanResult(\n            source_name=source_name,\n            total_rows=len(df),\n            columns_scanned=len(df.columns),\n            pii_found=pii_found,\n            risk_summary=risk_summary,\n            recommendations=recommendations,\n            scan_duration_seconds=round(duration, 3)\n        )\n    \n    def _generate_recommendations(self, pii_found: List[PIIDetection]) -> List[str]:\n        recs = []\n        risk_levels = [p.risk_level for p in pii_found]\n        \n        if RiskLevel.CRITICO in risk_levels:\n            recs.append(\"‚ö†Ô∏è URGENTE: Dados de risco CR√çTICO detectados. Aplicar anonimiza√ß√£o imediata.\")\n        if RiskLevel.ALTO in risk_levels:\n            recs.append(\"üî¥ Dados de risco ALTO requerem consentimento expl√≠cito ou anonimiza√ß√£o.\")\n        if any(p.pii_type == PIIType.CPF for p in pii_found):\n            recs.append(\"üìã CPFs detectados devem ser armazenados com criptografia ou hash.\")\n        if any(p.pii_type == PIIType.SALARY for p in pii_found):\n            recs.append(\"üí∞ Dados salariais s√£o sens√≠veis - considerar generaliza√ß√£o em faixas.\")\n        recs.append(\"üìù Documentar finalidade e base legal para tratamento de cada tipo de dado.\")\n        recs.append(\"üîí Implementar controle de acesso baseado em necessidade (need-to-know).\")\n        \n        return recs\n\nclass DataAnonymizer:\n    \"\"\"Anonimizador de dados com m√∫ltiplos m√©todos\"\"\"\n    \n    def __init__(self):\n        self.fake = Faker('pt_BR')\n        self.token_mapping = {}\n        self.salt = \"lgpd_demo_2024\"\n    \n    def clear_token_mapping(self):\n        self.token_mapping = {}\n    \n    def anonymize_column(self, df: pd.DataFrame, column: str, method: AnonymizationMethod, **kwargs) -> pd.DataFrame:\n        df = df.copy()\n        \n        if method == AnonymizationMethod.MASK:\n            df[column] = df[column].apply(lambda x: self._mask(str(x), **kwargs))\n        elif method == AnonymizationMethod.HASH:\n            df[column] = df[column].apply(lambda x: self._hash(str(x), **kwargs))\n        elif method == AnonymizationMethod.PSEUDONYMIZE:\n            df[column] = df[column].apply(lambda x: self._pseudonymize(**kwargs))\n        elif method == AnonymizationMethod.GENERALIZE:\n            df[column] = self._generalize(df[column], **kwargs)\n        elif method == AnonymizationMethod.SUPPRESS:\n            df[column] = kwargs.get('replacement', '[SUPRIMIDO]')\n        elif method == AnonymizationMethod.TOKENIZE:\n            df[column] = df[column].apply(lambda x: self._tokenize(str(x), **kwargs))\n        elif method == AnonymizationMethod.NOISE:\n            df[column] = df[column].apply(lambda x: self._add_noise(x, **kwargs))\n        \n        return df\n    \n    def _mask(self, value: str, visible_start: int = 3, visible_end: int = 2, **kwargs) -> str:\n        if len(value) <= visible_start + visible_end:\n            return '*' * len(value)\n        masked = value[:visible_start] + '*' * (len(value) - visible_start - visible_end)\n        if visible_end > 0:\n            masked += value[-visible_end:]\n        return masked\n    \n    def _hash(self, value: str, truncate: int = 16, **kwargs) -> str:\n        salted = f\"{self.salt}{value}\"\n        hashed = hashlib.sha256(salted.encode()).hexdigest()\n        return hashed[:truncate]\n    \n    def _pseudonymize(self, pii_type: str = 'name', **kwargs) -> str:\n        if pii_type == 'name':\n            return self.fake.name()\n        elif pii_type == 'email':\n            return self.fake.email()\n        elif pii_type == 'cpf':\n            return self.fake.cpf()\n        return self.fake.word()\n    \n    def _generalize(self, series: pd.Series, bins: int = 4, labels: List[str] = None, **kwargs) -> pd.Series:\n        if pd.api.types.is_numeric_dtype(series):\n            if labels is None:\n                labels = [f'Faixa {i+1}' for i in range(bins)]\n            return pd.cut(series, bins=bins, labels=labels)\n        return series.apply(lambda x: str(x)[:4] + '...' if len(str(x)) > 4 else str(x))\n    \n    def _tokenize(self, value: str, prefix: str = 'TOK_', **kwargs) -> str:\n        if value not in self.token_mapping:\n            self.token_mapping[value] = f\"{prefix}{len(self.token_mapping):05d}\"\n        return self.token_mapping[value]\n    \n    def _add_noise(self, value: Any, noise_level: float = 0.1, **kwargs) -> Any:\n        if isinstance(value, (int, float)):\n            noise = np.random.uniform(-noise_level, noise_level) * value\n            return round(value + noise, 2)\n        return value\n    \n    def anonymize_dataframe(self, df: pd.DataFrame, config: Dict[str, Dict]) -> pd.DataFrame:\n        df = df.copy()\n        for column, params in config.items():\n            if column in df.columns:\n                method = AnonymizationMethod(params.pop('method'))\n                df = self.anonymize_column(df, column, method, **params)\n                params['method'] = method.value  # Restaurar para config\n        return df\n\n# Cores do tema\nCORES = {\n    'critico': '#DC3545',\n    'alto': '#FD7E14',\n    'medio': '#FFC107',\n    'baixo': '#28A745',\n    'primaria': '#2E86AB',\n    'secundaria': '#A23B72'\n}\n\nprint('‚úÖ Sistema de Compliance LGPD carregado!')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gerando Dados de Exemplo\n",
    "\n",
    "Vamos criar um dataset fict√≠cio que simula dados de clientes com v√°rios tipos de PII (Personally Identifiable Information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados fict√≠cios\n",
    "fake = Faker('pt_BR')\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_registros = 100\n",
    "\n",
    "df_clientes = pd.DataFrame({\n",
    "    'id': range(1, n_registros + 1),\n",
    "    'nome_completo': [fake.name() for _ in range(n_registros)],\n",
    "    'cpf': [fake.cpf() for _ in range(n_registros)],\n",
    "    'email': [fake.email() for _ in range(n_registros)],\n",
    "    'telefone': [fake.phone_number() for _ in range(n_registros)],\n",
    "    'data_nascimento': [fake.date_of_birth(minimum_age=18, maximum_age=80).strftime('%d/%m/%Y') for _ in range(n_registros)],\n",
    "    'endereco': [fake.street_address() for _ in range(n_registros)],\n",
    "    'cidade': [fake.city() for _ in range(n_registros)],\n",
    "    'cep': [fake.postcode() for _ in range(n_registros)],\n",
    "    'salario': np.random.uniform(1500, 25000, n_registros).round(2),\n",
    "    'cargo': np.random.choice(['Analista', 'Gerente', 'Diretor', 'Assistente', 'Coordenador'], n_registros),\n",
    "    'departamento': np.random.choice(['TI', 'RH', 'Financeiro', 'Comercial', 'Opera√ß√µes'], n_registros),\n",
    "    'observacao': ['Cadastro regular' for _ in range(n_registros)]\n",
    "})\n",
    "\n",
    "print(f'üìä Dataset gerado: {len(df_clientes)} registros, {len(df_clientes.columns)} colunas')\n",
    "print(f'\\nColunas: {list(df_clientes.columns)}')\n",
    "df_clientes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scanner de PII - Detectando Dados Pessoais\n",
    "\n",
    "O scanner analisa cada coluna em busca de:\n",
    "- **Padr√µes regex**: CPF, CNPJ, e-mail, telefone, etc.\n",
    "- **Nomes de colunas**: \"nome\", \"endereco\", \"salario\", etc.\n",
    "- **Caracter√≠sticas estat√≠sticas**: Formatos t√≠picos de PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar scanner\n",
    "scanner = PIIScanner()\n",
    "\n",
    "# Executar scan\n",
    "resultado = scanner.scan(df_clientes, source_name='dados_clientes.csv')\n",
    "\n",
    "print('=' * 70)\n",
    "print('RESULTADO DO SCAN DE DADOS PESSOAIS')\n",
    "print('=' * 70)\n",
    "print(f'\\nüìÑ Arquivo: {resultado.source_name}')\n",
    "print(f'üìä Linhas analisadas: {resultado.total_rows}')\n",
    "print(f'üìù Colunas analisadas: {resultado.columns_scanned}')\n",
    "print(f'‚ö†Ô∏è  PIIs encontrados: {len(resultado.pii_found)}')\n",
    "print(f'‚è±Ô∏è  Tempo de scan: {resultado.scan_duration_seconds}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detalhes dos PIIs encontrados\n",
    "print('\\n' + '=' * 70)\n",
    "print('DETALHES DOS DADOS PESSOAIS ENCONTRADOS')\n",
    "print('=' * 70)\n",
    "\n",
    "for pii in resultado.pii_found:\n",
    "    icone = {\n",
    "        'critico': 'üö®',\n",
    "        'alto': 'üî¥',\n",
    "        'medio': 'üü°',\n",
    "        'baixo': 'üü¢'\n",
    "    }.get(pii.risk_level.value, '‚Ä¢')\n",
    "    \n",
    "    print(f'\\n{icone} [{pii.risk_level.value.upper()}] {pii.column}')\n",
    "    print(f'   Tipo: {pii.pii_type.value}')\n",
    "    print(f'   Detec√ß√£o: {pii.detection_method}')\n",
    "    print(f'   Ocorr√™ncias: {pii.count} ({pii.percentage}%)')\n",
    "    print(f'   Exemplos: {pii.sample_values[:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualiza√ß√£o: Matriz de Risco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados para visualiza√ß√£o\n",
    "df_pii = pd.DataFrame([\n",
    "    {\n",
    "        'coluna': pii.column,\n",
    "        'tipo': pii.pii_type.value,\n",
    "        'risco': pii.risk_level.value,\n",
    "        'ocorrencias': pii.count,\n",
    "        'metodo': pii.detection_method\n",
    "    }\n",
    "    for pii in resultado.pii_found\n",
    "])\n",
    "\n",
    "# Ordenar por risco\n",
    "ordem_risco = ['critico', 'alto', 'medio', 'baixo']\n",
    "df_pii['risco_ordem'] = df_pii['risco'].map({r: i for i, r in enumerate(ordem_risco)})\n",
    "df_pii = df_pii.sort_values('risco_ordem')\n",
    "\n",
    "# Gr√°fico de barras por risco\n",
    "cores_risco = [CORES.get(r, '#999') for r in df_pii['risco']]\n",
    "\n",
    "fig = px.bar(\n",
    "    df_pii,\n",
    "    x='coluna',\n",
    "    y='ocorrencias',\n",
    "    color='risco',\n",
    "    color_discrete_map=CORES,\n",
    "    text='tipo',\n",
    "    hover_data=['metodo']\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'text': 'üö® PIIs Detectados por Coluna e N√≠vel de Risco', 'x': 0.5, 'font': {'size': 18}},\n",
    "    xaxis_title='Coluna',\n",
    "    yaxis_title='Ocorr√™ncias',\n",
    "    xaxis_tickangle=-45,\n",
    "    height=500,\n",
    "    legend_title='N√≠vel de Risco'\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='outside')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo por n√≠vel de risco\n",
    "resumo_risco = df_pii.groupby('risco').size().reindex(ordem_risco).fillna(0).astype(int)\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(\n",
    "    labels=resumo_risco.index,\n",
    "    values=resumo_risco.values,\n",
    "    marker_colors=[CORES.get(r, '#999') for r in resumo_risco.index],\n",
    "    hole=0.4,\n",
    "    textinfo='label+value',\n",
    "    textposition='outside'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'text': 'üìä Distribui√ß√£o por N√≠vel de Risco', 'x': 0.5, 'font': {'size': 18}},\n",
    "    height=400,\n",
    "    annotations=[dict(text=f'{len(resultado.pii_found)}<br>PIIs', x=0.5, y=0.5, font_size=20, showarrow=False)]\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print('\\nüìù Resumo de Risco:')\n",
    "for nivel, count in resumo_risco.items():\n",
    "    if count > 0:\n",
    "        print(f'   {nivel.upper()}: {count} coluna(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Recomenda√ß√µes de Compliance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '=' * 70)\n",
    "print('üìú RECOMENDA√á√ïES DE COMPLIANCE (LGPD)')\n",
    "print('=' * 70)\n",
    "\n",
    "for i, rec in enumerate(resultado.recommendations, 1):\n",
    "    print(f'\\n{i}. {rec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Anonimiza√ß√£o de Dados\n",
    "\n",
    "O sistema oferece **7 m√©todos de anonimiza√ß√£o** para proteger dados pessoais:\n",
    "\n",
    "| M√©todo | Descri√ß√£o | Revers√≠vel? |\n",
    "|--------|-----------|------------|\n",
    "| `mask` | Substitui caracteres por * | N√£o |\n",
    "| `hash` | Hash SHA-256 com salt | N√£o |\n",
    "| `pseudonymize` | Substitui por dado falso | N√£o |\n",
    "| `generalize` | Reduz precis√£o (faixas) | N√£o |\n",
    "| `suppress` | Remove completamente | N√£o |\n",
    "| `tokenize` | Substitui por token √∫nico | Sim |\n",
    "| `noise` | Adiciona varia√ß√£o aleat√≥ria | N√£o |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar anonimizador\n",
    "anonymizer = DataAnonymizer()\n",
    "\n",
    "# Copiar dados originais\n",
    "df_original = df_clientes.copy()\n",
    "\n",
    "print('üîí DataAnonymizer inicializado')\n",
    "print('\\nM√©todos dispon√≠veis:')\n",
    "for method in AnonymizationMethod:\n",
    "    print(f'   ‚Ä¢ {method.value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Demonstra√ß√£o de Cada M√©todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de cada m√©todo\n",
    "amostra = df_original.head(5).copy()\n",
    "\n",
    "print('=' * 80)\n",
    "print('DEMONSTRA√á√ÉO DOS M√âTODOS DE ANONIMIZA√á√ÉO')\n",
    "print('=' * 80)\n",
    "\n",
    "# 1. MASK\n",
    "print('\\nüé≠ 1. MASK (Mascaramento)')\n",
    "print('-' * 40)\n",
    "df_mask = anonymizer.anonymize_column(amostra.copy(), 'cpf', AnonymizationMethod.MASK, \n",
    "                                       visible_start=3, visible_end=2)\n",
    "print(f'Original: {amostra[\"cpf\"].iloc[0]}')\n",
    "print(f'Masked:   {df_mask[\"cpf\"].iloc[0]}')\n",
    "\n",
    "# 2. HASH\n",
    "print('\\n#Ô∏è‚É£ 2. HASH (SHA-256 + Salt)')\n",
    "print('-' * 40)\n",
    "df_hash = anonymizer.anonymize_column(amostra.copy(), 'cpf', AnonymizationMethod.HASH, truncate=16)\n",
    "print(f'Original: {amostra[\"cpf\"].iloc[0]}')\n",
    "print(f'Hashed:   {df_hash[\"cpf\"].iloc[0]}')\n",
    "\n",
    "# 3. PSEUDONYMIZE\n",
    "print('\\nüë§ 3. PSEUDONYMIZE (Dados Falsos)')\n",
    "print('-' * 40)\n",
    "df_pseudo = anonymizer.anonymize_column(amostra.copy(), 'nome_completo', AnonymizationMethod.PSEUDONYMIZE, \n",
    "                                         pii_type='name')\n",
    "print(f'Original: {amostra[\"nome_completo\"].iloc[0]}')\n",
    "print(f'Pseudo:   {df_pseudo[\"nome_completo\"].iloc[0]}')\n",
    "\n",
    "# 4. GENERALIZE\n",
    "print('\\nüìä 4. GENERALIZE (Faixas)')\n",
    "print('-' * 40)\n",
    "df_gen = anonymizer.anonymize_column(amostra.copy(), 'salario', AnonymizationMethod.GENERALIZE, \n",
    "                                      bins=4, labels=['Baixo', 'M√©dio', 'Alto', 'Muito Alto'])\n",
    "print(f'Original: R$ {amostra[\"salario\"].iloc[0]:,.2f}')\n",
    "print(f'General.: {df_gen[\"salario\"].iloc[0]}')\n",
    "\n",
    "# 5. SUPPRESS\n",
    "print('\\n‚ùå 5. SUPPRESS (Remo√ß√£o)')\n",
    "print('-' * 40)\n",
    "df_sup = anonymizer.anonymize_column(amostra.copy(), 'telefone', AnonymizationMethod.SUPPRESS, \n",
    "                                      replacement='[SUPRIMIDO]')\n",
    "print(f'Original: {amostra[\"telefone\"].iloc[0]}')\n",
    "print(f'Supresso: {df_sup[\"telefone\"].iloc[0]}')\n",
    "\n",
    "# 6. TOKENIZE\n",
    "print('\\nüé´ 6. TOKENIZE (Token Revers√≠vel)')\n",
    "print('-' * 40)\n",
    "anonymizer.clear_token_mapping()  # Limpar tokens anteriores\n",
    "df_token = anonymizer.anonymize_column(amostra.copy(), 'email', AnonymizationMethod.TOKENIZE, \n",
    "                                        prefix='EMAIL_')\n",
    "print(f'Original: {amostra[\"email\"].iloc[0]}')\n",
    "print(f'Token:    {df_token[\"email\"].iloc[0]}')\n",
    "\n",
    "# 7. NOISE\n",
    "print('\\nüé≤ 7. NOISE (Ru√≠do Aleat√≥rio)')\n",
    "print('-' * 40)\n",
    "df_noise = anonymizer.anonymize_column(amostra.copy(), 'salario', AnonymizationMethod.NOISE, \n",
    "                                        noise_level=0.1)\n",
    "print(f'Original: R$ {amostra[\"salario\"].iloc[0]:,.2f}')\n",
    "print(f'Com Ru√≠do: R$ {df_noise[\"salario\"].iloc[0]:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Anonimiza√ß√£o Completa do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√£o de anonimiza√ß√£o por coluna\n",
    "config_anonimizacao = {\n",
    "    'nome_completo': {'method': 'pseudonymize', 'pii_type': 'name'},\n",
    "    'cpf': {'method': 'hash', 'truncate': 12},\n",
    "    'email': {'method': 'mask', 'visible_start': 2, 'visible_end': 0},\n",
    "    'telefone': {'method': 'mask', 'pattern': '(**) *****-****'},\n",
    "    'data_nascimento': {'method': 'generalize', 'generalization_type': 'truncate'},\n",
    "    'endereco': {'method': 'suppress', 'replacement': '[PROTEGIDO]'},\n",
    "    'cep': {'method': 'mask', 'visible_start': 5, 'visible_end': 0},\n",
    "    'salario': {'method': 'generalize', 'bins': 5, 'labels': ['At√© 3k', '3k-6k', '6k-10k', '10k-15k', 'Acima 15k']}\n",
    "}\n",
    "\n",
    "print('üìù Configura√ß√£o de Anonimiza√ß√£o:')\n",
    "for col, params in config_anonimizacao.items():\n",
    "    print(f'   {col}: {params[\"method\"]}')\n",
    "\n",
    "# Aplicar anonimiza√ß√£o\n",
    "anonymizer_full = DataAnonymizer()\n",
    "df_anonimizado = anonymizer_full.anonymize_dataframe(df_original.copy(), config_anonimizacao)\n",
    "\n",
    "print(f'\\n‚úÖ Dataset anonimizado com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Compara√ß√£o: Antes vs Depois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar antes e depois\n",
    "print('=' * 100)\n",
    "print('COMPARA√á√ÉO: DADOS ORIGINAIS vs ANONIMIZADOS')\n",
    "print('=' * 100)\n",
    "\n",
    "colunas_comparar = ['nome_completo', 'cpf', 'email', 'telefone', 'salario']\n",
    "\n",
    "for col in colunas_comparar:\n",
    "    print(f'\\nüìå {col.upper()}')\n",
    "    print(f'   Original:    {df_original[col].iloc[0]}')\n",
    "    print(f'   Anonimizado: {df_anonimizado[col].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o tabular\n",
    "comparacao = pd.DataFrame({\n",
    "    'Coluna': colunas_comparar,\n",
    "    'Original': [str(df_original[col].iloc[0])[:30] for col in colunas_comparar],\n",
    "    'Anonimizado': [str(df_anonimizado[col].iloc[0])[:30] for col in colunas_comparar],\n",
    "    'M√©todo': [config_anonimizacao.get(col, {}).get('method', '-') for col in colunas_comparar]\n",
    "})\n",
    "\n",
    "fig = go.Figure(data=[go.Table(\n",
    "    header=dict(\n",
    "        values=['<b>Coluna</b>', '<b>Original</b>', '<b>Anonimizado</b>', '<b>M√©todo</b>'],\n",
    "        fill_color=CORES['primaria'],\n",
    "        font=dict(color='white', size=13),\n",
    "        align='left',\n",
    "        height=35\n",
    "    ),\n",
    "    cells=dict(\n",
    "        values=[comparacao[col] for col in comparacao.columns],\n",
    "        fill_color=[['#f8f9fa', 'white'] * 3],\n",
    "        font=dict(size=12),\n",
    "        align='left',\n",
    "        height=30\n",
    "    )\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'text': 'üîí Compara√ß√£o: Dados Originais vs Anonimizados', 'x': 0.5, 'font': {'size': 18}},\n",
    "    height=300\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Verifica√ß√£o P√≥s-Anonimiza√ß√£o\n",
    "\n",
    "Vamos executar o scanner novamente para verificar se os dados ainda cont√™m PIIs detect√°veis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan p√≥s-anonimiza√ß√£o\n",
    "resultado_pos = scanner.scan(df_anonimizado, source_name='dados_anonimizados.csv')\n",
    "\n",
    "# Comparar resultados\n",
    "print('=' * 70)\n",
    "print('COMPARA√á√ÉO: ANTES vs DEPOIS DA ANONIMIZA√á√ÉO')\n",
    "print('=' * 70)\n",
    "\n",
    "metricas = pd.DataFrame({\n",
    "    'M√©trica': ['PIIs Detectados', 'Risco Cr√≠tico', 'Risco Alto', 'Risco M√©dio', 'Risco Baixo'],\n",
    "    'Antes': [\n",
    "        len(resultado.pii_found),\n",
    "        resultado.risk_summary.get('critico', 0),\n",
    "        resultado.risk_summary.get('alto', 0),\n",
    "        resultado.risk_summary.get('medio', 0),\n",
    "        resultado.risk_summary.get('baixo', 0)\n",
    "    ],\n",
    "    'Depois': [\n",
    "        len(resultado_pos.pii_found),\n",
    "        resultado_pos.risk_summary.get('critico', 0),\n",
    "        resultado_pos.risk_summary.get('alto', 0),\n",
    "        resultado_pos.risk_summary.get('medio', 0),\n",
    "        resultado_pos.risk_summary.get('baixo', 0)\n",
    "    ]\n",
    "})\n",
    "\n",
    "metricas['Redu√ß√£o'] = metricas['Antes'] - metricas['Depois']\n",
    "metricas['Redu√ß√£o %'] = ((metricas['Antes'] - metricas['Depois']) / metricas['Antes'].replace(0, 1) * 100).round(1)\n",
    "\n",
    "print(metricas.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico comparativo\n",
    "fig = go.Figure()\n",
    "\n",
    "categorias = ['Cr√≠tico', 'Alto', 'M√©dio', 'Baixo']\n",
    "valores_antes = [resultado.risk_summary.get(c.lower(), 0) for c in ['critico', 'alto', 'medio', 'baixo']]\n",
    "valores_depois = [resultado_pos.risk_summary.get(c.lower(), 0) for c in ['critico', 'alto', 'medio', 'baixo']]\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Antes',\n",
    "    x=categorias,\n",
    "    y=valores_antes,\n",
    "    marker_color=CORES['secundaria'],\n",
    "    text=valores_antes,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Depois',\n",
    "    x=categorias,\n",
    "    y=valores_depois,\n",
    "    marker_color=CORES['primaria'],\n",
    "    text=valores_depois,\n",
    "    textposition='outside'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title={'text': 'üìä Redu√ß√£o de Risco Ap√≥s Anonimiza√ß√£o', 'x': 0.5, 'font': {'size': 18}},\n",
    "    xaxis_title='N√≠vel de Risco',\n",
    "    yaxis_title='Quantidade de Colunas',\n",
    "    barmode='group',\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sum√°rio Executivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular redu√ß√£o total de risco\n",
    "pii_antes = len(resultado.pii_found)\n",
    "pii_depois = len(resultado_pos.pii_found)\n",
    "reducao_total = ((pii_antes - pii_depois) / pii_antes * 100) if pii_antes > 0 else 100\n",
    "\n",
    "print('=' * 70)\n",
    "print('SUM√ÅRIO EXECUTIVO - AUDITORIA LGPD')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'''\n",
    "üìÑ DATASET ANALISADO\n",
    "   Registros: {len(df_original):,}\n",
    "   Colunas: {len(df_original.columns)}\n",
    "   Fonte: dados_clientes.csv\n",
    "\n",
    "üîç SCAN DE DADOS PESSOAIS\n",
    "   PIIs detectados (antes): {pii_antes}\n",
    "   Riscos cr√≠ticos: {resultado.risk_summary.get('critico', 0)}\n",
    "   Riscos altos: {resultado.risk_summary.get('alto', 0)}\n",
    "\n",
    "üîí ANONIMIZA√á√ÉO APLICADA\n",
    "   Colunas processadas: {len(config_anonimizacao)}\n",
    "   M√©todos utilizados: {len(set(c['method'] for c in config_anonimizacao.values()))}\n",
    "\n",
    "üìä RESULTADO\n",
    "   PIIs ap√≥s anonimiza√ß√£o: {pii_depois}\n",
    "   Redu√ß√£o de risco: {reducao_total:.1f}%\n",
    "\n",
    "‚úÖ STATUS: {'CONFORME' if reducao_total >= 80 else 'REQUER ATEN√á√ÉO'}\n",
    "''')\n",
    "\n",
    "print('=' * 70)\n",
    "print('Refer√™ncias LGPD aplicadas:')\n",
    "print('   ‚Ä¢ Art. 5¬∫, II - Dado anonimizado')\n",
    "print('   ‚Ä¢ Art. 12 - Anonimiza√ß√£o como alternativa')\n",
    "print('   ‚Ä¢ Art. 6¬∫, III - Princ√≠pio da necessidade')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Exportar Dados Anonimizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Salvar dados anonimizados\nimport os\n\n# Criar diret√≥rio de sa√≠da (funciona tanto local quanto no Colab)\noutput_dir = 'output'\nos.makedirs(output_dir, exist_ok=True)\n\narquivo_saida = os.path.join(output_dir, 'dados_anonimizados.csv')\ndf_anonimizado.to_csv(arquivo_saida, index=False, encoding='utf-8-sig')\n\ntamanho_kb = os.path.getsize(arquivo_saida) / 1024\n\nprint(f'‚úÖ Dados anonimizados salvos em: {arquivo_saida}')\nprint(f'   Registros: {len(df_anonimizado):,}')\nprint(f'   Tamanho: {tamanho_kb:.1f} KB')\n\n# No Colab, oferecer download\ntry:\n    from google.colab import files\n    files.download(arquivo_saida)\n    print('üì• Download iniciado automaticamente!')\nexcept:\n    pass  # N√£o est√° no Colab"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üöÄ Pr√≥ximos Passos\n",
    "\n",
    "Este notebook demonstrou o fluxo completo de auditoria e anonimiza√ß√£o LGPD.\n",
    "\n",
    "**Para usar o sistema via CLI:**\n",
    "\n",
    "```bash\n",
    "# Scan de arquivo\n",
    "python main.py scan dados.csv --report\n",
    "\n",
    "# Anonimiza√ß√£o\n",
    "python main.py anonymize dados.csv --config config.json\n",
    "```\n",
    "\n",
    "**Recursos adicionais:**\n",
    "- Relat√≥rio HTML detalhado\n",
    "- Configura√ß√£o JSON para anonimiza√ß√£o\n",
    "- Logs de auditoria\n",
    "\n",
    "---\n",
    "\n",
    "*Desenvolvido como parte do Portf√≥lio de Data Science*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}